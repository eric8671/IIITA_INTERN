{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1kPeYKUSSFpqAGgwXWnvDaP7HHgo5zcuM","authorship_tag":"ABX9TyN9DCGH6T2Y4QaUxqF1Zj4n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pwd\n","!cd\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xh3jOIGqhRJ8","executionInfo":{"status":"ok","timestamp":1686806810150,"user_tz":-330,"elapsed":1103,"user":{"displayName":"ANMOL RAMANI","userId":"10946061780274937935"}},"outputId":"9afe41d4-66ba-436a-83a2-8dddb351adeb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Fp8tMAVXaPpW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686807494939,"user_tz":-330,"elapsed":6230,"user":{"displayName":"ANMOL RAMANI","userId":"10946061780274937935"}},"outputId":"4d87aa43-6935-43cf-f474-7eb44d84097c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","\n","import sys\n","sys.path.insert(0,'/content/drive/MyDrive/IIIT A D2GAN/D2GAN-master/D2GAN-master')\n","import models\n","import utils\n","import torch.nn as nn\n","import torch\n","from torch.autograd import Variable\n","import torchvision.utils as vutils\n","\n","\n"],"metadata":{"id":"Ywh6kukbeGRy","executionInfo":{"status":"ok","timestamp":1686807494942,"user_tz":-330,"elapsed":9,"user":{"displayName":"ANMOL RAMANI","userId":"10946061780274937935"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["pip install utils"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wOAiJbSyuYqy","executionInfo":{"status":"ok","timestamp":1686739082259,"user_tz":-330,"elapsed":5117,"user":{"displayName":"ANMOL RAMANI","userId":"10946061780274937935"}},"outputId":"3733cb85-dd1a-4837-d43c-1715dc16e56f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting utils\n","  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n","Installing collected packages: utils\n","Successfully installed utils-1.0.1\n"]}]},{"cell_type":"code","execution_count":12,"metadata":{"id":"dkj6u6JafoU6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686807533688,"user_tz":-330,"elapsed":17632,"user":{"displayName":"ANMOL RAMANI","userId":"10946061780274937935"}},"outputId":"967c2694-269b-4022-86e7-3c736ade3a3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:13<00:00, 12667753.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data/\n"]}],"source":["train_loader = utils.load_data_CIFAR10()"]},{"cell_type":"code","source":["if not os.path.exists('./result'):\n","    os.mkdir('result/')\n","\n","if not os.path.exists('./model'):\n","    os.mkdir('model/')"],"metadata":{"id":"HIN6KZZcg7_y","executionInfo":{"status":"ok","timestamp":1686807552696,"user_tz":-330,"elapsed":946,"user":{"displayName":"ANMOL RAMANI","userId":"10946061780274937935"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# import torch\n","# import torch.nn as nn\n","\n","\n","# ngft = 64\n","# ngf=tf.convert_to_tensor(\n","#     ngft, dtype=None, dtype_hint=None, name=None)\n","# ndft= 64\n","# ndf= tf.convert_to_tensor(\n","#     ndft, dtype=None, dtype_hint=None, name=None\n","# )\n","# nzt = 100\n","# nz = tf.convert_to_tensor(\n","#     nzt, dtype=None, dtype_hint=None, name=None\n","# )\n","# nct = 3\n","# nc = tf.convert_to_tensor(\n","#     nct, dtype=None, dtype_hint=None, name=None\n","# )"],"metadata":{"id":"bO-oW6X3jhjq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","nz = 100\n","nc = 3\n","ngf = 64\n","ndf = 64\n","\n","class _netG(nn.Module):\n","    def __init__(self):\n","        super(_netG, self).__init__()\n","        self.main = nn.Sequential(\n","\n","            # Z\n","            nn.ConvTranspose2d(nz, ngf*8, 2, 1, 0, bias=False),\n","            nn.BatchNorm2d(ngf * 8),\n","            nn.ReLU(True),\n","\n","            # (ngf * 8) x 2 x 2\n","            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 4),\n","            nn.ReLU(True),\n","\n","            # (ngf * 4) x 4 x 4\n","            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf*2),\n","            nn.ReLU(True),\n","\n","            # (ngf * 2) x 8 x 8\n","            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf),\n","            nn.ReLU(),\n","\n","            # ngf x 16 x 16\n","            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n","            nn.Tanh()\n","        )\n","    def forward(self, input):\n","        output = self.main(input)\n","        return output\n"],"metadata":{"id":"n3a6H1wTmMLX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class _netD(nn.Module):\n","    def __init__(self):\n","        super(_netD, self).__init__()\n","        self.main = nn.Sequential(\n","            # (nc) x 32 x 32\n","            nn.Conv2d(nc, ndf, 4,2,1,bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            # ndf x 16 x 16\n","            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            # (ndf * 2) x 8 x 8\n","            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            # (ndf * 4) x 4 x 4\n","            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf*8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            # (ndf * 8) x 2 x 2\n","            nn.Conv2d(ndf*8, 1, 2, 1, 0, bias=False),\n","            nn.Softplus()\n","        )\n","    def forward(self, input):\n","        output = self.main(input)\n","        return output.view(-1, 1).squeeze(1)\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:         # Conv weight init\n","        m.weight.data.normal_(0.0, 0.01)\n","    elif classname.find('BatchNorm') != -1:  # BatchNorm weight init\n","        m.weight.data.normal_(1.0, 0.02)\n","        m.bias.data.fill_(0)\n"],"metadata":{"id":"0dPK1RR7mdeu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SjJxIk_Er0Iq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" netG=get_netG()\n"," netD1=get_netD()\n"," netD2=get_netD()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A4NlIKwlta68","executionInfo":{"status":"ok","timestamp":1686739697280,"user_tz":-330,"elapsed":1400,"user":{"displayName":"ANMOL RAMANI","userId":"10946061780274937935"}},"outputId":"9ec95d21-0fcd-41b4-fe2c-a9de0043866f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["USE CUDA\n","USE CUDA\n","USE CUDA\n"]}]},{"cell_type":"code","source":["optimizerD1 = torch.optim.Adam(netD1.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","optimizerD2 = torch.optim.Adam(netD2.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","optimizerG = torch.optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))"],"metadata":{"id":"DbdiZiJrtpOq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Log_loss(torch.nn.Module):\n","    def __init__(self):\n","        # negation is true when you minimize -log(val)\n","        super(Log_loss, self).__init__()\n","\n","    def forward(self, x, negation=True):\n","        # shape of x will be [batch size]\n","        log_val = torch.log(x)\n","        loss = torch.sum(log_val)\n","        if negation:\n","            loss = torch.neg(loss)\n","        return loss\n","\n","class Itself_loss(torch.nn.Module):\n","    def __init__(self):\n","        super(Itself_loss, self).__init__()\n","\n","    def forward(self, x, negation=True):\n","        # shape of x will be [batch size]\n","        loss = torch.sum(x)\n","        if negation:\n","            loss = torch.neg(loss)\n","        return loss\n"],"metadata":{"id":"L1mrM7YltulK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion_log=Log_loss()\n","criterion_itself=Itself_loss()\n"],"metadata":{"id":"AzLNAs9Otw-R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input = torch.FloatTensor(64, 3, 64, 64)\n","noise = torch.FloatTensor(64, 100, 1, 1)\n","fixed_noise = torch.FloatTensor(64, 100, 1, 1).normal_(0, 1)\n","fixed_noise = Variable(fixed_noise)\n","fixed_noise = torch.Tensor(fixed_noise)\n","\n"],"metadata":{"id":"vYOWkeVHuINN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["use_cuda = torch.cuda.is_available()\n","if use_cuda:\n","    criterion_log, criterion_itself = criterion_log.cuda(),  criterion_itself.cuda()\n","    input= input.cuda()\n","    noise, fixed_noise = noise.cuda(), fixed_noise.cuda\n","\n"],"metadata":{"id":"xg-VPEsZyWIh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(200):\n","    for i, data in enumerate(train_loader):\n","        real_cpu, _ = data\n","        batch_size = real_cpu.size(0)\n","        ######################################\n","        # train D1 and D2\n","        #####################################\n","\n","        netD1.zero_grad()\n","        netD2.zero_grad()\n","        # train with real\n","        if use_cuda:\n","            real_cpu = real_cpu.cuda()\n","\n","        input.resize_as_(real_cpu).copy_(real_cpu)\n","        inputv = Variable(input)\n","\n","        # D1 sees real as real, minimize -logD1(x)\n","        output = netD1(inputv)\n","        errD1_real = 0.2 * criterion_log(output)#criterion(output1, labelv) * 0.2\n","        errD1_real.backward()\n","\n","        # D2 sees real as fake, minimize D2(x)\n","        output = netD2(inputv)\n","        errD2_real = criterion_itself(output, False)\n","        errD2_real.backward()\n","\n","        # train with fake\n","        noise.resize_(batch_size, 100, 1, 1).normal_(0,1)\n","        noisev = Variable(noise)\n","        fake = netG(noisev)\n","\n","        # D1 sees fake as fake, minimize D1(G(z))\n","        output = netD1(fake.detach())\n","        errD1_fake = criterion_itself(output, False)\n","        errD1_fake.backward()\n","\n","        # D2 sees fake as real, minimize -log(D2(G(z))\n","        output = netD2(fake.detach())\n","        errD2_fake = 0.1 * criterion_log(output)\n","        errD2_fake.backward()\n","\n","        optimizerD1.step()\n","        optimizerD2.step()\n","\n","        ##################################\n","        # train G\n","        ##################################\n","        netG.zero_grad()\n","        # G: minimize -D1(G(z)): to make D1 see fake as real\n","        output = netD1(fake)\n","        errG1 = criterion_itself(output)\n","\n","        # G: minimize logD2(G(z)): to make D2 see fake as fake\n","        output = netD2(fake)\n","        errG2 = criterion_log(output, False)\n","\n","        errG = errG2*0.1 + errG1\n","        errG.backward()\n","        optimizerG.step()\n","\n","        if ((i+1) % 200 == 0):\n","            print(i+1, \"step\")\n","            print(str(errG1.item()) + \" \" + str(errG2.item()*0.1))\n","            fake = netG(fixed_noise)\n","            if use_cuda:\n","                vutils.save_image(fake.cpu().data, '%s/fake_samples_epoch_%s.png' % ('/content/drive/MyDrive/IIIT A D2GAN/results', str(epoch)+\"_\"+str(i+1)), normalize=True)\n","            else:\n","                vutils.save_image(fake.data, '%s/fake_samples_epoch_%s.png' % ('/content/drive/MyDrive/IIIT A D2GAN/results', str(epoch)+\"_\"+str(i+1)), normalize=True)\n","    print(\"%s epoch finished\" % (str(epoch)))\n","    print(\"-----------------------------------------------------------------\\n\")\n","    fake = netG(fixed_noise)\n","    if use_cuda:\n","        vutils.save_image(fake.cpu().data, '%s/fake_samples_epoch_%s.png' % ('/content/drive/MyDrive/IIIT A D2GAN/results', str(epoch)+\"_\"+str(i+1)), normalize=True)\n","    else:\n","        vutils.save_image(fake.data, '%s/fake_samples_epoch_%s.png' % ('/content/drive/MyDrive/IIIT A D2GAN/results', str(epoch)+\"_\"+str(i+1)), normalize=True)\n","    torch.save(netG.state_dict(), '%s/netG.pth' % ('model'))\n","    torch.save(netD1.state_dict(), '%s/netD1.pth' % ('model'))\n","    torch.save(netD2.state_dict(), '%s/netD2.pth' % ('model'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"84C9H18NyfsT","executionInfo":{"status":"error","timestamp":1686741005844,"user_tz":-330,"elapsed":593,"user":{"displayName":"ANMOL RAMANI","userId":"10946061780274937935"}},"outputId":"52900b6f-c9b6-4853-a58e-9de23ae3f9f2"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-9a984d5070b2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# D1 sees real as real, minimize -logD1(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0merrD1_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcriterion_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#criterion(output1, labelv) * 0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0merrD1_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-9c2b0d443a2a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     27\u001b[0m         )\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mweights_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"]}]}]}